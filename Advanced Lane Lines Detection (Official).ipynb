{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial some 'global parameters'\n",
    "# Is there a better to do so?\n",
    "isInit = True\n",
    "[leftx, lefty, rightx, righty, left_fit, right_fit, M, invM, xm_per_pix, ym_per_pix] = \\\n",
    "            [None for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def plot2images(img1, img2, title1=None, title2=None):\n",
    "    f, (ax1, ax2) = plt.subplots(1,2, figsize=(20, 15))\n",
    "    ax1.set_title(title1, fontsize=25)\n",
    "    if len(img1.shape) == 3:\n",
    "        ax1.imshow(img1)\n",
    "    else:\n",
    "        ax1.imshow(img1, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=25)\n",
    "    if len(img2.shape) == 3:\n",
    "        ax2.imshow(img2)\n",
    "    else:\n",
    "        ax2.imshow(img2, cmap='gray')\n",
    "        \n",
    "def addText(img, lc, rc, co):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, 'Left curv: '+str(lc)[:6]+' Right curv: '+ \\\n",
    "                str(rc)[:6], (90,80), font, 1.5,(255,255,255),3,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.putText(img, 'Vehicle is ' + str(co)[:4] + ' meter left of center', (90,150), \\\n",
    "                font, 1.5,(255,255,255),3,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "### Aim\n",
    "Get the `mxt` and `dist` for undistortion later.\n",
    "\n",
    "### Steps\n",
    "* Setup `objpoints` (same for all images)\n",
    "* Find `imgpoints` (corners found by `cv2.findChessboardCorners()`)\n",
    "* Use `cv2.calibrateCamera()` get the `mxt` and `dist`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_path = './camera_cal/'\n",
    "\n",
    "def cam_cal(cal_path, nx, ny):\n",
    "    files = glob.glob(cal_path + '*')\n",
    "    \n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    objpoints, imgpoints = [], []\n",
    "\n",
    "    for file in files:\n",
    "        img = cv2.imread(file)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny))\n",
    "\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check What I Get in `Camera Calibration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx, ny = 9, 6\n",
    "mtx, dist = cam_cal(cal_path, nx, ny)\n",
    "img = cv2.imread('camera_cal/calibration3.jpg')\n",
    "undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "gray = cv2.cvtColor(undst, cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (nx, ny))\n",
    "\n",
    "if ret == True:\n",
    "    undst = cv2.drawChessboardCorners(undst, (nx, ny), corners, ret)\n",
    "    plot2images(img, undst, 'Original', 'Undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "### Aim\n",
    "Combine thresholdings to build a binary image.\n",
    "\n",
    "### Steps\n",
    "* `Color threshold` (L and S)\n",
    "* `Gradient threshold`\n",
    "    * Sobelx\n",
    "    * Direction\n",
    "    * Magnitude\n",
    "* Fuse these two thresholdings with `or`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=150):\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sobelx and sobely\n",
    "    if orient == 'x':\n",
    "        sobel = np.abs(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    else:\n",
    "        sobel = np.abs(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "\n",
    "    # scale to 8bit\n",
    "    scaled_sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "\n",
    "    # create a mask\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & ((scaled_sobel <= thresh_max)) ] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=5, mag_thresh=(50, 150)):\n",
    "    \n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sobelx and sobely\n",
    "    sobelX = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobelY = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "\n",
    "    magSobel = np.sqrt(np.power(sobelX, 2) + np.power(sobelY, 2))\n",
    "    \n",
    "    # scale to 8bit\n",
    "    scaled_sobel = np.uint8(255 * magSobel / np.max(magSobel))\n",
    "\n",
    "    # create a mask\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & ((scaled_sobel <= mag_thresh[1])) ] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3)):\n",
    "    \n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sobelx and sobely\n",
    "    sobelX = np.abs(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    sobelY = np.abs(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "\n",
    "    arctan = np.arctan2(sobelY, sobelX)\n",
    "\n",
    "    # create a mask\n",
    "    binary_output = np.zeros_like(arctan)\n",
    "    binary_output[(arctan >= thresh[0]) & (arctan <= thresh[1])] = 1\n",
    "    return binary_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_thresh(img):\n",
    "    # Read in an image\n",
    "    mag = mag_thresh(img)\n",
    "    dir = dir_threshold(img)\n",
    "    absX = abs_sobel_thresh(img, orient='x')\n",
    "    absY = abs_sobel_thresh(img, orient='y')\n",
    "\n",
    "    binary_output = np.zeros_like(mag)\n",
    "    # With no absY condition to get more nonzeros and augment the binary image\n",
    "    # & (absY==1)\n",
    "    binary_output[(mag==1) & (dir==1) |(absX==1)] = 1.0\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def color_thresh(img, err_thresh=200000):\n",
    "    # Combined L and S channels\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)/255\n",
    "    threshold1 = 0.55\n",
    "#     threshold1 = 1\n",
    "    sat = hls[:,:,2]\n",
    "    sat_binary = sat > threshold1\n",
    "    \n",
    "    lightness = hls[:,:,1]\n",
    "    threshold2 = 0.47\n",
    "#     threshold2 = 1\n",
    "    lit_binary = lightness > threshold2\n",
    "\n",
    "    combined = np.logical_or(sat_binary, lit_binary)\n",
    "    \n",
    "    # If L channel ruins the information then not combine it (Only S channel instead)\n",
    "    if combined[combined==True].shape[0] < err_thresh:\n",
    "        out_img = combined + 0.0\n",
    "    elif sat_binary[sat_binary==True].shape[0] < err_thresh:\n",
    "        out_img = sat_binary + 0.0\n",
    "    else:\n",
    "        # If S channel is still not working, only use grad_thresh\n",
    "        out_img = np.zeros_like(sat)\n",
    "    \n",
    "    return out_img\n",
    "\n",
    "def fused_thresh(color, grad):\n",
    "    return np.array(np.logical_or(color, grad) * 255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check What I Get in `Thresholding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('test_images/test4.jpg')\n",
    "undst = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "grad = grad_thresh(undst)\n",
    "color = color_thresh(undst)\n",
    "\n",
    "fused = fused_thresh(color, grad)\n",
    "plot2images(color, grad, 'Color Thresh', 'Gradient Thresh')\n",
    "plt.figure()\n",
    "plt.title('Fused', fontsize=25)\n",
    "plt.imshow(fused, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp\n",
    "### Aim\n",
    "Input an image and output its warped perspective form (birds-eye view).\n",
    "\n",
    "### Steps\n",
    "* Undistort the input using `mxt` and `dist` got in previous step\n",
    "* Specify an area like masking\n",
    "* Warp the area into **birds-eye view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_warp_M(width=1280, height=720):\n",
    "    src = np.array([[585, 455],[696, 455],[240, 680],[1060, 680]], dtype=np.float32)\n",
    "\n",
    "    offset = 300\n",
    "    dest = np.array([[offset, 0], [width-offset, 0], [offset, height], [width-offset, height]], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src, dest)\n",
    "#     invM = np.linalg.inv(M)\n",
    "    invM = cv2.getPerspectiveTransform(dest, src)\n",
    "    return M, invM\n",
    "\n",
    "def Warp(img, M):\n",
    "    height, width = img.shape\n",
    "    warped = cv2.warpPerspective(img, M, (width, height))\n",
    "\n",
    "    return warped\n",
    "\n",
    "def Unwarp(img, invM):\n",
    "    height, width = img.shape[0], img.shape[1], \n",
    "    unwarped = cv2.warpPerspective(img, invM, (width, height))\n",
    "    return unwarped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check What I Get in `Warp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M, invM = get_warp_M()\n",
    "warped= Warp(fused, M)\n",
    "unwarped = Unwarp(warped, invM)\n",
    "plt.imshow(unwarped, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Windows\n",
    "### Aim\n",
    "Find lane lines through `Sliding windows` for initialization.\n",
    "\n",
    "### Steps\n",
    "* Find points in windows\n",
    "* Calculate the mean of x-axis each window as the center\n",
    "* Draw windows and color the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Binary Image\n",
    "# Output: Windows Drew Image\n",
    "def slide_windows(img):\n",
    "    out_img = np.dstack((img, img, img))\n",
    "\n",
    "    height, width = img.shape\n",
    "    mid_point = width // 2\n",
    "\n",
    "    margin = 80\n",
    "\n",
    "    nWin = 9\n",
    "    winLen = np.int(height // nWin)\n",
    "    minPix = 60\n",
    "\n",
    "    lBase, rBase = np.argmax(np.sum(img[:,:mid_point], axis=0)), \\\n",
    "            mid_point + np.argmax(np.sum(img[:,mid_point:], axis=0))\n",
    "\n",
    "    lCur, rCur = lBase, rBase\n",
    "\n",
    "    nonzerox = np.nonzero(img)[1]\n",
    "    nonzeroy = np.nonzero(img)[0]\n",
    "\n",
    "    # store all the points within windows\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    for i in range(nWin):\n",
    "        # from bottom to top of a image\n",
    "        y_high = height - i * winLen\n",
    "        y_low = y_high - winLen\n",
    "\n",
    "        xleft_low = lCur - margin\n",
    "        xleft_high = lCur + margin\n",
    "        xright_low = rCur - margin\n",
    "        xright_high = rCur + margin\n",
    "\n",
    "        good_left_inds = ((nonzeroy >= y_low) & (nonzeroy <= y_high) & \\\n",
    "                          (nonzerox >= xleft_low) & (nonzerox <= xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= y_low) & (nonzeroy <= y_high) & \\\n",
    "                           (nonzerox >= xright_low) & (nonzerox <= xright_high)).nonzero()[0]\n",
    "        \n",
    "        if nonzerox[good_left_inds].shape[0] < minPix:\n",
    "            pass\n",
    "        else:\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            lWinMean = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            xleft_low = lWinMean - margin\n",
    "            xleft_high = lWinMean + margin\n",
    "            cv2.rectangle(out_img,(xleft_low, y_low),\\\n",
    "                (xleft_high, y_high),(0, 255, 0), 2)\n",
    "            lCur = lWinMean\n",
    "\n",
    "        if nonzerox[good_right_inds].shape[0] < minPix:\n",
    "            pass\n",
    "        else:\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            rWinMean = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            xright_low = rWinMean - margin\n",
    "            xright_high = rWinMean + margin\n",
    "            cv2.rectangle(out_img,(xright_low, y_low),\\\n",
    "                (xright_high, y_high),(0, 255, 0), 2)\n",
    "            rCur = rWinMean\n",
    "            \n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    return out_img, leftx, lefty, rightx, righty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check What I Get in Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, leftx, lefty, rightx, righty = slide_windows(warped)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial\n",
    "### Aim\n",
    "Fit the points with a second polynomial and use the polynomial to replace the sliding windows.\n",
    "\n",
    "### Steps\n",
    "* Fit `polynomial`\n",
    "* Find the points in the virtual windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Binary Image\n",
    "# Output: Windows Drew Image\n",
    "\n",
    "def polynomial_find_lanes(img, leftx, lefty, rightx, righty):\n",
    "    out_img = np.dstack((img, img, img))\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    window_img_yellow = np.zeros_like(out_img)\n",
    "    img_shape = out_img.shape\n",
    "\n",
    "    margin = 80\n",
    "\n",
    "    # Polynomial fitting\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Find points within the margin\n",
    "    nonzerox = np.nonzero(img)[1]\n",
    "    nonzeroy = np.nonzero(img)[0]\n",
    "\n",
    "    xleft_center = left_fit[0] * nonzeroy ** 2 + left_fit[1] * nonzeroy + left_fit[2]\n",
    "    xright_center = right_fit[0] * nonzeroy ** 2 + right_fit[1] * nonzeroy + right_fit[2]\n",
    "\n",
    "    left_lane_inds = ((nonzerox >= xleft_center - margin) & (nonzerox <= xleft_center + margin)).nonzero()[0]\n",
    "    right_lane_inds = ((nonzerox >= xright_center - margin) & (nonzerox <= xright_center + margin)).nonzero()[0]\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Visualize the right pts\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Visualize the polynomial lines\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    left_pts = np.array([np.stack((left_fitx, ploty),axis=1)], dtype=np.int32)\n",
    "    right_pts = np.array([np.stack((right_fitx, ploty),axis=1)], dtype=np.int32)\n",
    "    \n",
    "\n",
    "    # Visualize the detection area\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))\n",
    "    \n",
    "    cv2.polylines(window_img_yellow, left_pts, False, (0, 255, 255), thickness=5) \n",
    "    cv2.polylines(window_img_yellow, right_pts, False, (0, 255, 255), thickness=5) \n",
    "    \n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img_yellow, 1, 0)\n",
    "    return out_img, leftx, lefty, rightx, righty, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check What I Get in Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, leftx, lefty, rightx, righty, left_fit, right_fit = polynomial_find_lanes(warped, leftx, lefty, rightx, righty)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Curvature\n",
    "### Aim\n",
    "Measuring curvature through the polynomial function\n",
    "\n",
    "### Steps\n",
    "* Turn pixels into real world meters\n",
    "* Fit a meter-based polynomial\n",
    "* Measure the curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_basic(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def get_realworld_scalar():\n",
    "    img = cv2.imread('./test_images/straight_lines1.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    mid = np.int(width // 2)\n",
    "    \n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img = cv2.Canny(img, 140, 270)\n",
    "    lines = cv2.HoughLinesP(img, rho=1, theta=np.pi/180, \\\n",
    "                    threshold=9, minLineLength=3, maxLineGap=8)\n",
    "    draw_lines_basic(img, lines)\n",
    "    img = Warp(img, M)\n",
    "    thres = 180\n",
    "    img[img>thres] = 255\n",
    "    img[img<=thres] = 0\n",
    "    \n",
    "    nonzerox = np.nonzero(img)[1]\n",
    "    nonzeroy = np.nonzero(img)[0]\n",
    "    \n",
    "    dashed_lane = nonzeroy[(nonzerox >= mid) & (nonzeroy >= 360) & (nonzeroy <= 540)]\n",
    "    y_low = np.min(dashed_lane)\n",
    "    y_high = np.max(dashed_lane)\n",
    "    \n",
    "    left_offset = 250\n",
    "    right_offset = 900\n",
    "    \n",
    "    left_sub_img = img[height-50:height, left_offset:400]\n",
    "    right_sub_img = img[height-50:height, right_offset:1000]\n",
    "    \n",
    "    left_mean = np.mean(left_sub_img, axis=0)\n",
    "    right_mean = np.mean(right_sub_img, axis=0)\n",
    "\n",
    "    plt.plot(left_mean, 'darkorange')\n",
    "    plt.plot(right_mean, 'dodgerblue')\n",
    "    plt.show()\n",
    "    \n",
    "    x_low = np.argmax(left_mean[70:]) + left_offset + 70\n",
    "    x_high = np.argmax(right_mean[:70]) + right_offset\n",
    "    \n",
    "    y_offset = 20\n",
    "    print(x_high-x_low, y_high-y_low)\n",
    "    \n",
    "    return 3.7/(x_high-x_low), 3/(y_high-y_low-y_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature(img, leftx, lefty, rightx, righty):\n",
    "    global xm_per_pix, ym_per_pix\n",
    "    img_shape = img.shape\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    if xm_per_pix is None:\n",
    "        xm_per_pix, ym_per_pix = get_realworld_scalar()\n",
    "\n",
    "    y_eval = (img.shape[0] - 1) * ym_per_pix\n",
    "\n",
    "    left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    left_curverad = (1 + (2 * left_fit_cr[0] * y_eval + left_fit_cr[1]) ** 2 ) ** (3/2) / np.abs(2 * left_fit_cr[0])\n",
    "    right_curverad = (1 + (2 * right_fit_cr[0] * y_eval + right_fit_cr[1]) ** 2 ) ** (3/2) / np.abs(2 * right_fit_cr[0])\n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def measure_car_offset(height, width, left_fit, right_fit):\n",
    "    y_eval = height - 10\n",
    "    x_mid = np.int(width / 2)\n",
    "    \n",
    "    left_x = (left_fit[0] * y_eval ** 2 + left_fit[1] * y_eval + left_fit[2]).astype(np.int32)\n",
    "    right_x = (right_fit[0] * y_eval ** 2 + right_fit[1] * y_eval + right_fit[2]).astype(np.int32)\n",
    "\n",
    "    img_mid = np.int((left_x + right_x) / 2)\n",
    "    \n",
    "    return xm_per_pix * (img_mid - x_mid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check What I Get in Measuring Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measure_curvature(warped, leftx, lefty, rightx, righty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "### Aim\n",
    "Visualize curvature and lane lines\n",
    "\n",
    "### Steps\n",
    "* Inputing\n",
    "* Undistortion\n",
    "* Thresholding\n",
    "* Warping\n",
    "* Detection\n",
    "    * Sliding Windows\n",
    "    * Polylines\n",
    "* Measuring curvature\n",
    "* Unwarping detected lane lines\n",
    "* Adding curvature to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    global isInit, leftx, lefty, rightx, righty, left_fit, right_fit, M, invM\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # Thresholding\n",
    "    grad = grad_thresh(undst)\n",
    "    color = color_thresh(undst)\n",
    "    fused = fused_thresh(color, grad)\n",
    "    height, width = fused.shape[0], fused.shape[1]\n",
    "    # Warping\n",
    "    if M is None:\n",
    "        M, invM = get_warp_M()\n",
    "    warped = Warp(fused, M)\n",
    "    \n",
    "    if isInit:\n",
    "        isInit = False\n",
    "        # Detection - Sliding Windows\n",
    "        sw_img, leftx, lefty, rightx, righty = slide_windows(warped)\n",
    "\n",
    "    # Detection - Polylines\n",
    "    poly_img, leftx, lefty, rightx, righty, left_fit, right_fit = \\\n",
    "                polynomial_find_lanes(warped, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    car_offset = measure_car_offset(height, width, left_fit, right_fit)\n",
    "    \n",
    "    # Measure curvature\n",
    "    left_curv, right_curv = measure_curvature(warped, leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Visualize the polynomial lines\n",
    "    out_img = np.dstack((warped, warped, warped))\n",
    "    img_shape = warped.shape\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0]).astype(np.int32)\n",
    "\n",
    "    left_fitx = (left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]).astype(np.int32)\n",
    "    right_fitx = (right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]).astype(np.int32)\n",
    "\n",
    "    # Visualize the Lane lines and Area between them\n",
    "    line_left_margin = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    line_right_margin = np.array([np.flipud(np.transpose(np.vstack([right_fitx, \n",
    "                              ploty])))])\n",
    "    area_pts = np.hstack((line_left_margin, line_right_margin))\n",
    "    cv2.fillPoly(window_img, np.int_([area_pts]), (0, 255, 0))\n",
    "\n",
    "    left_pts = np.array([np.stack((left_fitx, ploty),axis=1)], dtype=np.int32)\n",
    "    right_pts = np.array([np.stack((right_fitx, ploty),axis=1)], dtype=np.int32)\n",
    "\n",
    "    cv2.polylines(window_img, left_pts, False, (0, 255, 255), thickness=10) \n",
    "    cv2.polylines(window_img, right_pts, False, (0, 255, 255), thickness=10) \n",
    "\n",
    "    window_img = Unwarp(window_img, invM)\n",
    "    out_img = cv2.addWeighted(undst, 1, window_img, 0.4, 0)\n",
    "\n",
    "    return out_img, left_curv, right_curv, car_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isInit = True\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "img, lc, rc, co = pipeline(img)\n",
    "addText(img,lc,rc, co)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('./test_images/*')\n",
    "for file in files:\n",
    "    img = cv2.imread(file)\n",
    "    isInit=True\n",
    "    result = pipeline(img)[0]\n",
    "    cv2.imwrite('output_images/' + file.split('/')[-1], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    img, lc, rc, co  = pipeline(image)\n",
    "    addText(img, lc, rc, co)\n",
    "    return img\n",
    "\n",
    "isInit = True \n",
    "white_output = 'test_videos_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
